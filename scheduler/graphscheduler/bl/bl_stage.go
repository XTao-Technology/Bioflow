/* 
 Copyright (c) 2016-2017 XTAO technology <www.xtaotech.com>
 All rights reserved.

 Redistribution and use in source and binary forms, with or without
 modification, are permitted provided that the following conditions
 are met:
  1. Redistributions of source code must retain the above copyright
     notice, this list of conditions and the following disclaimer.
  2. Redistributions in binary form must reproduce the above copyright
     notice, this list of conditions and the following disclaimer in the
     documentation and/or other materials provided with the distribution.
 
  THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS'' AND
  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
  ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE
  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
  OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
  HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
  LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
  OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
  SUCH DAMAGE.
*/
package bl

import (
    "fmt"
    "os"
    "strings"
    "time"
    "errors"
    
    . "github.com/xtao/bioflow/blparser"
    . "github.com/xtao/bioflow/common"
    . "github.com/xtao/bioflow/message"
    . "github.com/xtao/bioflow/storage"
    . "github.com/xtao/bioflow/scheduler/common"
)

const TMP_DIR string = "BIOFLOW_DIR_USE_TO_HACK_MEGER_WHEN_PARENT_DIR_NOT_EMPTY"

/*
 * blCmdStage is to hold all information to run
 * a command in a docker image. It gets basic
 * information from pipeline item definition,
 * and build actual execution facility by resolving
 * placeholders
 */
type blCmdStage struct {
    BaseStageInfo

    /*
     * cmd: input by user in pipeline item, has placeholders
     *      to represent input/output
     */
    cmd       string

    /*
     * execCommand: the command generated by bioflow to replace
     *      placeholders of cmd with correct value. It is the
     *      command to be executed in the Docker image
     */
    execCommand string


    /*
     * Holds the pointer of nodes that produce
     * the input we need. The key is the named
     * input tag.
     */
    inputFileNodeMap *NamedNodeMap

    /*
     * Holds the pointer of nodes that produce
     * the output directory we need
     *
     */
    inputDirNodeMap *NamedNodeMap

    /*
     * inputMap holds all the variables. It is 
     * shared in whole system and can't be modified
     */
    inputMap map[string]string

    /*
     * the output name is prefix used when creating
     * the output file name
     */
    outputName string

    /*
     * input file list for $files.* like input. only
     * non nil in ShardFiles stage
     */
    inputFiles []string

    /*
     * holds the branch variables used by this stage.
     * shared with others and can't be modified.
     */
    branchVarMap map[string]string

    /* 
     * track volumes need map to container for this
     * stage.
     */
    conVolMgr *ContainerVolMgr

    /*output file list indexed by name*/
    outputFilesMap map[string]string
    shadowOutputFilesMap map[string]string
    outputDirsMap map[string]string
    shadowOutputDirsMap map[string]string

    /*the tag and extension name map*/
    extensionName string
    extensionMap map[string]string

    /*the tag prefix and tag prefix map*/
    tagPrefix string
    tagPrefixMap map[string]string

    /*
     * The shadown work directory is a temporary 
     * work directory for a stage. Each retry will
     * have a different shadow work directory. When
     * the stage is done, all the files in the final
     * shadow work directory will be moved to its target
     * location under its work directory.
     */
    shadowWorkDir string

    /* the directory the output files wrote to */
    outputDir string
    outputRelToWorkDir bool
    shadowOutputDir string

    /* the constraints placed on nodes running the stage*/
    constraints map[string]string
}

func NewBlCmdStage(job Job, id string, cmd string, workdir string, 
    logdir string, inputFileNodeMap *NamedNodeMap, inputMap map[string]string,
    outputName string, restoreDataDir string) *blCmdStage {
	stage := &blCmdStage{
        BaseStageInfo: CreateBaseStageInfo(job, id, workdir, logdir, GRAPH_STAGE),
        cmd: cmd, 
        inputMap: inputMap, 
        inputFileNodeMap: inputFileNodeMap,
        outputName: outputName,
        extensionName: "",
        extensionMap: make(map[string]string),
        constraints: make(map[string]string),
	}
    dataDir, _, _ := GetStorageMgr().GetContainerExecDir()
    stage.conVolMgr = NewContainerVolMgr(dataDir, restoreDataDir)

    return stage
}

/*
 * Return the cmd which is input by user when creating the 
 * pipeline item and need calls BuildCommand to create exec
 * command with value assigned for placeholders
 */
func (stage *blCmdStage) Cmd() string {
    return stage.cmd
}

/*
 * Return the command of stage which is already built
 * with correct input, output and variable
 */
func (stage *blCmdStage) GetCommand() string {
    return stage.execCommand
}

func (stage *blCmdStage) SetCommand(cmd string) {
    stage.execCommand = cmd
}

func (stage *blCmdStage) SetTagPrefix(tagPrefix string,
    tagPrefixMap map[string]string) {
    stage.tagPrefix = tagPrefix
    stage.tagPrefixMap = tagPrefixMap
}

func (stage *blCmdStage) AddConstraints(constraints map[string]string) {
    for k, v := range constraints {
        stage.constraints[k] = v
    }
}

func (stage *blCmdStage) Constraints() map[string]string {
    return stage.constraints
}

func (stage *blCmdStage) SetInputFiles(files []string) {
    stage.inputFiles = files
}

func (stage *blCmdStage) SetBranchVarMap(vars map[string]string) {
    stage.branchVarMap = vars
}

func (stage *blCmdStage) GetDataVolsMap() (error, []*DataVol) {
    return stage.conVolMgr.GetMappedVols()
}

func (stage *blCmdStage) ExtensionMap() map[string]string {
    return stage.extensionMap
}

func (stage *blCmdStage) SetExtensionMap(nameMap map[string]string) {
    for k, v := range nameMap {
        stage.extensionMap[k] = v
    }
}

func (stage *blCmdStage) ExtensionName() string {
    return stage.extensionName
}

func (stage *blCmdStage) SetExtensionName(name string) {
    stage.extensionName = name
}

func (stage *blCmdStage) CheckExtensionMap(nameMap map[string]string) bool {
    for k, _ := range nameMap {
        if !strings.Contains(stage.cmd, k) {
            return false
        }
    }
    return true
}

func (stage *blCmdStage) CheckExtensionName(name string) bool {
    outputTags, _ := stage._GetOutputTags()
    if len(outputTags) > 1 {
        return false
    } else {
        return true
    }
}

func (stage *blCmdStage) ClearShadowDir() {
    stage.shadowWorkDir = ""
    stage.shadowOutputDir = ""
}

func (stage *blCmdStage) ShadowWorkDir() string {
    return stage.shadowWorkDir
}

func (stage *blCmdStage) ShadowOutputDir() string {
    return stage.shadowOutputDir
}

func (stage *blCmdStage) OutputDir() string {
    if stage.outputRelToWorkDir {
        return stage.WorkDir() + "/" + stage.outputDir
    }

    return stage.outputDir
}

func (stage *blCmdStage) _OutputDir() string {
    return stage.outputDir
}

func (stage *blCmdStage) SetOutputDir(dir string, rel bool) {
    stage.outputDir = dir
    stage.outputRelToWorkDir = rel
}

func (stage *blCmdStage) OutputDirIsRel() bool {
    return stage.outputRelToWorkDir
}

/* shadow work directory is temporal directories which
 * storing the stages' output files. when stage is done,
 * these files are move to the target work directories
 */
func (stage *blCmdStage) PrepareShadowDir(create bool) error {
    shadowDirPath := stage.WorkDir() + fmt.Sprintf("/shadow-%s-run-%d",
        stage.ID(), stage.RetryCount())
    secCtxt := stage.Job().GetSecurityContext()
    accountInfo := secCtxt.GetUserInfo()
    if create {
        err := GetStorageMgr().MkdirOnScheduler(shadowDirPath, true,
            accountInfo)
        if err != nil {
            return err
        }
    }
    stage.shadowWorkDir = shadowDirPath

    SchedulerLogger.Debugf("Stage %s works on shadow work dir %s\n",
        stage.GetID(), stage.shadowWorkDir)

    /*
     * Don't create shadow output dir if user not specify
     * a separate output directory
     */
    if stage.outputDir == "" {
        return nil
    }

    if stage.outputRelToWorkDir {
        shadowDirPath = fmt.Sprintf("%s/%s",
            stage.shadowWorkDir, stage.outputDir)
    } else {
        shadowDirPath = fmt.Sprintf("%s-shadow-%s-run-%d",
            stage.outputDir, stage.ID(), stage.RetryCount())
    }
    if create {
        err := GetStorageMgr().MkdirOnScheduler(shadowDirPath, true, accountInfo)
        if err != nil {
            return err
        }
    }
    stage.shadowOutputDir = shadowDirPath

    SchedulerLogger.Debugf("Stage %s works on shadow output dir %s\n",
        stage.GetID(), stage.shadowOutputDir)

    return nil
}

/*
 * It Merges the shadow output dir which may have depth > 1.
 * Be consistent with the PrepareShadowDir func.
 */
func (stage *blCmdStage) BuildStageShadowOutputDir(shadowDirPath string) string {
    if stage.outputRelToWorkDir {
        items := strings.Split(stage.outputDir, "/")
        topPath := ""
        for i := 0; i < len(items); i ++ {
            if items[i] != "" {
                topPath += "/" + items[i]
                break
            }
        }
        if topPath != "" {
            shadowDirPath = fmt.Sprintf("%s/%s",
                stage.shadowWorkDir, topPath)
        } else {
            SchedulerLogger.Debugf("No need delete empty shadow output dir\n")
            return shadowDirPath
        }
    }
    return shadowDirPath
}

func (stage *blCmdStage) SetInputDirNodeMap(dirMap *NamedNodeMap) {
    stage.inputDirNodeMap = dirMap
}

/*
 * Maps vol@cluster:filepath format to container based path, it will
 * collect the volume mapping information during this process.
 */
func (stage *blCmdStage) MapDataPathToContainer(file string) string {
    err, path := stage.conVolMgr.MapDataPathToContainer("", file)
    if err != nil {
        SchedulerLogger.Errorf("Can't map file %s: %s\n", file,
            err.Error())
        return ""
    }

    return path
}

func (stage *blCmdStage) MapDirToContainer(dirPath string,
    dirTarget string) error {
    return stage.conVolMgr.MapDirToContainer(dirPath, dirTarget)
}

func (stage *blCmdStage) GetOutputDir(tag string, shadow bool) (error, string) {
    var dir string
    if tag == "" {
        tag = GB_TAG_LAST_OUTPUT
    }

    dir = stage.GetTargetOutputDir(tag, shadow)
    if dir == "" {
        return errors.New("Build output dir failure"),
        ""
    }

    return nil, stage.MapDataPathToContainer(dir)
}

/*This should be only called by the stage itself. because it will
  map the volume to container*/
func (stage *blCmdStage) GetOutput(tag string, isRealPath bool) (error, string) {
    var file string
    if tag == "" {
        tag = GB_TAG_LAST_OUTPUT
    }

    if isRealPath {
        file = stage.GetTargetOutput(tag)
        if file == "" {
            return errors.New("Build output file failure"),
            ""
        }
    } else {
        file = stage.GetShadowOutput(tag)
        if file == "" {
            return errors.New("Build output file failure"),
            ""
        }
    }
    return nil, stage.MapDataPathToContainer(file)
}

/*Build container relative work dir*/
func (stage *blCmdStage) BuildWorkDir() string {
    return stage.MapDataPathToContainer(stage.ShadowWorkDir())
}

func (stage *blCmdStage) BuildInputDir() string {
    dataset := stage.Job().InputDataSet()
    return stage.MapDataPathToContainer(dataset.InputDir())
}

func (stage *blCmdStage) _GetCanonizedOutputDir(tag string, shadow bool) string {
    stage._BuildOutputDirsMap(shadow)
    var dirMap map[string]string = nil
    if !shadow {
        dirMap = stage.outputDirsMap
    } else  {
        dirMap = stage.shadowOutputDirsMap
    }

    if dirMap != nil {
        if dirPath, ok := dirMap[tag]; ok {
            return dirPath
        } else if tag == GB_TAG_LAST_OUTPUT {
            if len(dirMap) == 1 {
                for _, dirValue := range dirMap {
                    return dirValue
                }
            }
        }
    }

    return ""
}

func (stage *blCmdStage) _ResetOutputDirsMap() {
    stage.shadowOutputDirsMap = nil
    stage.outputDirsMap = nil
}

func (stage *blCmdStage) _BuildOutputDirsMap(shadow bool) {
    if shadow && stage.shadowOutputDirsMap != nil {
        return
    } else if !shadow && stage.outputDirsMap != nil {
        return
    }

    _, outputDirTags := stage._GetOutputTags()
    if outputDirTags == nil {
        return
    }

    outputDir := ""
    if !shadow {
        outputDir = stage.WorkDir()
        if stage._OutputDir() != "" {
            outputDir = stage.OutputDir()
        }
    } else {
        outputDir = stage.ShadowWorkDir()
        if stage._OutputDir() != "" {
            outputDir = stage.ShadowOutputDir()
        }
    }
    outDirs := make(map[string]string)
    for i := 0; i < len(outputDirTags); i ++ {
        outputTag := outputDirTags[i]
        if outputTag == "" {
            outputTag = GB_TAG_LAST_OUTPUT
        }
        if _, ok := outDirs[outputTag]; !ok {
            outDirs[outputTag] = fmt.Sprintf("%s/%s",
                outputDir, outputTag)
            if outputTag != GB_TAG_LAST_OUTPUT {
                prefixedTag := stage._GetPrefixedTag(outputTag)
                if prefixedTag != "" {
                    outDirs[prefixedTag] = outDirs[outputTag]
                }
            }
        }
    }

    if shadow {
        stage.shadowOutputDirsMap = outDirs
    } else {
        stage.outputDirsMap = outDirs
    }
}

/*
  Canonized output return filename as vol@cluster:filepath format, it is used
  when other stages referenct it as a input
  */
func (stage *blCmdStage) _GetCanonizedOutput(tag string, shadow bool) string {
    stage._BuildOutputFilesMap(shadow)
    var fileMap map[string]string = nil
    if !shadow {
        fileMap = stage.outputFilesMap
    } else  {
        fileMap = stage.shadowOutputFilesMap
    }

    if fileMap != nil {
        if filePath, ok := fileMap[tag]; ok {
            return filePath
        } else if tag == GB_TAG_LAST_OUTPUT {
            if len(fileMap) == 1 {
                for _, fileValue := range fileMap {
                    return fileValue
                }
            }
        }
    }

    return ""
}

func (stage *blCmdStage) _ResetOutputFilesMap() {
    stage.shadowOutputFilesMap = nil
    stage.outputFilesMap = nil
}

func (stage *blCmdStage) _BuildOutputFilesMap(shadow bool) {
    var extensionName string
    var tmpOutputFileName string
    /* try to cache the output files map to avoid
     * reduandent work. Use the cache if it exists.
     */
    if shadow && stage.shadowOutputFilesMap != nil {
        return
    } else if !shadow && stage.outputFilesMap != nil {
        return
    }

    outputTags, _ := stage._GetOutputTags()
    if outputTags == nil {
        return
    }

    outputDir := ""
    if !shadow {
        outputDir = stage.WorkDir()
        if stage._OutputDir() != "" {
            outputDir = stage.OutputDir()
        }
    } else {
        outputDir = stage.ShadowWorkDir()
        if stage._OutputDir() != "" {
            outputDir = stage.ShadowOutputDir()
        }
    }

    /*
     * A non-empty output file means user specify the file name, we shouldn't
     * generate it ourselves
     */
    outputFile := stage.OutputFile()
    if outputFile == "" {
        outputFile = stage.outputName
    }
    outFiles := make(map[string]string)
    extensionMap := stage.ExtensionMap()
    outputFileMap := stage.OutputFileMap()
    for i := 0; i < len(outputTags); i ++ {
        outputTag := outputTags[i]
        if outputTag == "" {
            outputTag = GB_TAG_LAST_OUTPUT
        }
        extensionName = ""
        if extensionMap != nil && len(extensionMap) != 0 {
            if _, ok := extensionMap[outputTag]; ok {
                extensionName = extensionMap[outputTag]
            }
        } else if stage.ExtensionName() != "" {
            extensionName = stage.ExtensionName()
        }
        if extensionName == "" {
            extensionName = outputTag
        }
        if _, ok := outFiles[outputTag]; !ok {
            if _, ok := outputFileMap[outputTag]; ok {
                tmpOutputFileName = outputFileMap[outputTag]
            } else {
                tmpOutputFileName = outputFile
            }
            /*$output the outputfile is not with tag*/
            if outputTag == GB_TAG_LAST_OUTPUT {
                outFiles[outputTag] = fmt.Sprintf("%s/%s",
                    outputDir, tmpOutputFileName)
            } else {
                outFiles[outputTag] = fmt.Sprintf("%s/%s.%s",
                    outputDir, tmpOutputFileName, extensionName)
                prefixedTag := stage._GetPrefixedTag(outputTag)
                if prefixedTag != "" {
                    outFiles[prefixedTag] = outFiles[outputTag]
                }
            }
        }
    }

    if !shadow {
        stage.outputFilesMap = outFiles
    } else {
        stage.shadowOutputFilesMap = outFiles
    }
}

func (stage *blCmdStage) GetTargetOutputDir(tag string, shadow bool) string {
    return stage._GetCanonizedOutputDir(tag, shadow)
}

func (stage *blCmdStage) GetTargetOutput(tag string) string {
    return stage._GetCanonizedOutput(tag, false)
}


func (stage *blCmdStage) GetTargetOutputs() map[string]string {
    stage._BuildOutputFilesMap(false)
    return stage.outputFilesMap
}

func (stage *blCmdStage) GetShadowOutput(tag string) string {
    return stage._GetCanonizedOutput(tag, true)
}



/*If a stage reference last stage's output as input, it should use the
  path URI and map itself. Because the mapping process will collect all
  the volumes should be used by the container*/
func (stage *blCmdStage) BuildAllNodeInput(prefix string,
    name string) (error, string) {
    if stage.inputFileNodeMap == nil {
        return errors.New("No input named " + name), ""
    }

    nodes := stage.inputFileNodeMap.GetNamedNodes(name)
    if nodes == nil || len(nodes) == 0 {
        return errors.New("No input named " + name), ""
    }
    inputStr := ""
    for i := 0; i < len(nodes); i ++ {
        node := nodes[i]
        stageOutput := node.Stage().GetTargetOutput(name)
        /*track the input file for tagging*/
        stage.TrackInputFile(stageOutput)

        if inputStr == "" {
            inputStr = prefix + stage.MapDataPathToContainer(stageOutput)
        } else {
            inputStr += " " + prefix + stage.MapDataPathToContainer(stageOutput)
        }
    }

    return nil, inputStr
}

func (stage *blCmdStage) BuildAllFileInput(prefix string) (error, string) {
    inputStr := ""
    for i := 0; i < len(stage.inputFiles); i ++ {
        file := stage.inputFiles[i]
        /*track the input file for tagging*/
        stage.TrackInputFile(file)

        mappedFile := stage.MapDataPathToContainer(file)
        if mappedFile == "" {
            return errors.New("Fail to map file " + file),
                ""
        }

        if inputStr == "" {
            inputStr = prefix + mappedFile
        } else {
            inputStr += " " + prefix + mappedFile
        }
    }
    return nil, inputStr
}

func (stage *blCmdStage) BuildIndexedFileInput(prefix string,
    index int) (error, string) {
    inputStr := ""
    if stage.inputFiles == nil || index < 0 || index >= len(stage.inputFiles) {
        errMsg := fmt.Sprintf("No input file with index %d ",
            index + 1)
        return errors.New(errMsg), ""
    }
    file := stage.inputFiles[index]
    /*track the input file for tagging*/
    stage.TrackInputFile(file)

    mappedFile := stage.MapDataPathToContainer(file)
    if mappedFile == "" {
        return errors.New("Fail to map file " + file),
                ""
    }
    inputStr = prefix + mappedFile
    return nil, inputStr
}

/*If a stage reference last stage's output as input, it should use the
  path URI and map itself. Because the mapping process will collect all
  the volumes should be used by the container*/
func (stage *blCmdStage) BuildNodeInputFile(name string) (error, string) {
    if node, ok := stage.inputFileNodeMap.GetNamedNode(name); ok {
        stageOutput := node.Stage().GetTargetOutput(name)
        /*track the input file for tagging*/
        stage.TrackInputFile(stageOutput)

        return nil, stage.MapDataPathToContainer(stageOutput)
    } else {
        errMsg := fmt.Sprintf("The named %s input file not exist",
            name)
        SchedulerLogger.Errorf("Build Node input file failure: %s\n",
            errMsg)
        return errors.New(errMsg), ""
    }
}

func (stage *blCmdStage) BuildNodeIndexedInput(name string,
    index int) (error, string) {
    if node, ok := stage.inputFileNodeMap.GetIndexedNamedNode(name, index); ok {
        stageOutput := node.Stage().GetTargetOutput(name)
        /*track the input file for tagging*/
        stage.TrackInputFile(stageOutput)

        return nil, stage.MapDataPathToContainer(stageOutput)
    } else {
        errMsg := fmt.Sprintf("The named %s index %d input file not exist",
            name, index)
        SchedulerLogger.Infof("Build Node input file failure: %s\n",
            errMsg)
        return errors.New(errMsg), ""
    }
}

/**/
func (stage *blCmdStage) _BuildCmdInputDir(name string) (error, string) {
    if node, ok := stage.inputDirNodeMap.GetNamedNode(name); ok {
        stageOutput := node.Stage().GetTargetOutputDir(name, false)
        if stageOutput == "" {
            return nil, ""
        }

        return nil, stage.MapDataPathToContainer(stageOutput)
    } else {
        errMsg := fmt.Sprintf("The named %s input dir not exist",
            name)
        SchedulerLogger.Errorf("Build Node input dir failure: %s\n",
            errMsg)
        return nil, ""
    }
}

func (stage *blCmdStage) _BuildInputDir(name string) (error, string) {
    /*if the place holder is $inputdir, then match the job's input dir*/
    if name == "" {
        return nil, stage.BuildInputDir()
    }

    if node, ok := stage.inputDirNodeMap.GetNamedNode(name); ok {
        stageOutput := node.Stage().OutputDir()
        return nil, stage.MapDataPathToContainer(stageOutput)
    } else {
        errMsg := fmt.Sprintf("The named %s input dir not exist",
            name)
        SchedulerLogger.Infof("Build Node input dir failure: %s\n",
            errMsg)
        return errors.New(errMsg), ""
    }
}

func (stage *blCmdStage) BuildNodeInputDir(name string) (error, string) {
    if name == "" {
        return stage._BuildInputDir(name)
    }

    _, inputDir := stage._BuildCmdInputDir(name)
    if inputDir != "" {
        return nil, inputDir
    } else {
        return stage._BuildInputDir(name)
    }
}

func (stage *blCmdStage) BuildTagFile(name string) (error, string) {
    if fileStr, ok := stage.inputMap[name]; ok {
        /*track the input file for tagging*/
        stage.TrackInputFile(fileStr)

        return nil, stage.MapDataPathToContainer(fileStr) 
    } else {
        errMsg := fmt.Sprintf("The named %s input not exist",
            name)
        SchedulerLogger.Infof("Build Tag file failure: %s\n", errMsg)
        return errors.New(errMsg), ""
    }
}

func (stage *blCmdStage) BuildTagVariable(name string) (error, string) {
    if fileStr, ok := stage.inputMap[name]; ok {
        return nil, fileStr
    } else {
        errMsg := fmt.Sprintf("The named %s variable not exist ",
            name)
        SchedulerLogger.Infof("Build Tag Variable failure %s",
            errMsg)
        return errors.New(errMsg), ""
    }
}

func (stage *blCmdStage) BuildBranchVariable(name string) (error, string) {
    if varStr, ok := stage.branchVarMap[name]; ok {
        return nil, varStr
    } else {
        errMsg := fmt.Sprintf("The named %s branch variable not exist",
            name)
        SchedulerLogger.Infof("Build branch variable %s\n",
            errMsg)
        return errors.New(errMsg), ""
    }
}


/*
 * Prepare execution required work like:
 * 1) Build command
 * 2) Build and return work directory
 */
func (stage *blCmdStage) PrepareExecution(isRecovery bool) (error, *BuildStageErrorInfo, *StageExecEnv) {
    err := stage.PrepareShadowDir(!isRecovery)
    if err != nil {
        SchedulerLogger.Errorf("Fail to create shadow work directory: %s\n",
            err.Error())
        return err, nil, nil
    }

    workDir := stage.BuildWorkDir()
    if workDir == "" {
        SchedulerLogger.Errorf("Fail to build stage work directory\n")
        return errors.New("Fail to build stage work directory"),
            nil, nil
    }

    if FSUtilsIsHDFSPath(workDir) {
        /* The hdfs work direcotry can't be used by container
         * as work directory
         */
        SchedulerLogger.Infof("Change stage work directory from hdfs path %s to /\n",
            workDir)
        workDir = "/"
    }

    execEnv := &StageExecEnv {
        WorkDir: workDir,
        NetMode: CLUSTER_NET_DUPLEX_MODE,
        Privileged: stage.Privileged(),
        Env: stage.Env(),
        Volumes: stage.Volumes(),
    }

    /*
     * clear stage input file list before tracking them when
     * building the command
     */
    stage.ClearInputFileList()

    /*
     * Because each time retry, the shadow output files map
     * are different, so need invalidate the cached output
     * files map
     */
    stage._ResetOutputFilesMap()
    stage._ResetOutputDirsMap()

    /*
     * Try to collect all the shadow output files and directories
     */
    if !isRecovery {
        execEnv.OutputDirs, execEnv.OutputFiles = stage._GetShadowOutputDirsAndFiles()
    }

    buildStageErrInfo := stage.BuildCommand()
    if buildStageErrInfo != nil {
        SchedulerLogger.Errorf("Fail to build command: %s\n", buildStageErrInfo.ErrInfo)
        errMsg := fmt.Sprintf("Fail to build command: " + buildStageErrInfo.ErrInfo)
        return errors.New(errMsg), buildStageErrInfo, nil
    }

    return nil, nil, execEnv
}

/*Merge  shadowOutputDir to outputdir or shadowWorkdir to workdir*/
func (stage *blCmdStage) StageMergeDir(oldDir string, newDir string,
    preDeleteOperationFunc func(string) string) error {
    var retryCount int = 0
    storageMgr := GetStorageMgr()

retryMergeShadowDir:
    var subDir string
    var shadowDirPath string
    err := storageMgr.MergeDirFilesOnScheduler(oldDir, newDir, "dup-" + stage.GetID())
    if err != nil {
        if os.IsNotExist(err) {
            /*
             * When the ShadowOutputDir/shadowWorkDir is alread not exsit, it must be deleted some time
             * so the following repeat operations do not need to continue to CleanupShadowOutputDir.
             */
            return nil
        } else {
            return err
        }
    } else {
        SchedulerLogger.Infof("Succeed to merge shadow directory %s to target %s\n",
            oldDir, newDir)
    }

    if preDeleteOperationFunc != nil {
        shadowDirPath = preDeleteOperationFunc(oldDir)
    } else {
        shadowDirPath = oldDir
    }
    err = storageMgr.DeleteDirOnScheduler(shadowDirPath, true)
    if err != nil {
        if retryCount >= 10 {
            SchedulerLogger.Errorf("Fail to delete shadow dir %s: %s\n",
                    oldDir, err.Error())
            return err
        }
        /*Hack the situation which rm system call return directory not empty*/
        retryCount ++
        FSUtilsCountRetryNum()
        SchedulerLogger.Debugf("Delete shadow dir:%s,err:%s, so modify the parent dir dentry and retry, retryCount: %d!",
            oldDir, err.Error(), retryCount)
        subDir = oldDir + "/" + TMP_DIR
        FSUtilsMkdir(subDir, false)
        FSUtilsDeleteDir(subDir, false)
        goto retryMergeShadowDir
    }

    return nil
}

/*
 * Release the unused stage resources to save memory
 */
func (stage *blCmdStage) Recycle() {
    /*The Vol Mgr can be recycled now*/
    if stage.conVolMgr != nil {
        stage.conVolMgr.Destroy()
        stage.conVolMgr = nil
    }

    /*Recycle all the input tracking data structures*/
    stage.inputFileNodeMap = nil
    stage.inputDirNodeMap = nil
    stage.inputMap = nil
    stage.inputFiles = nil
    stage.branchVarMap = nil
    stage.SetIOAttr(nil)

    /*
     * Clear the tracked input files list. It may already be
     * cleared before reaching here in most cases. But re-clear
     * here to ensure it be done in all cases.
     */
    stage.ClearInputFileList()

    SchedulerLogger.Infof("Stage %s/%s resources are recycled\n",
        stage.GetID(), stage.Job().GetID())
}

/*
 * Called when the stage complete, it will delete the shadow work directory
 * and move output files to the target location
 */
func (stage *blCmdStage) PostExecution(success bool) error {
    var err error
    storageMgr := GetStorageMgr()
    if success {
        SchedulerLogger.Debugf("Do post work for success stage %s\n",
            stage.GetID())

        if stage.ShadowOutputDir() != "" {
            secCtxt := stage.Job().GetSecurityContext()
            outputDir := stage.OutputDir()
            err = GetStorageMgr().MkdirOnScheduler(outputDir, true, secCtxt.GetUserInfo())
            if err != nil {
                SchedulerLogger.Errorf("Can't create output directory %s: %s\n", outputDir,
                    err.Error())
                return err
            }

            err = stage.StageMergeDir(stage.ShadowOutputDir(), stage.OutputDir(), stage.BuildStageShadowOutputDir)
            if err != nil {
                SchedulerLogger.Infof("Fail to merge shadow output directory %s to target %s: %s\n",
                    stage.ShadowOutputDir(), stage.OutputDir(), err.Error())
                return err
            }
        }

        if stage.ShadowWorkDir() != "" {
            err = stage.StageMergeDir(stage.ShadowWorkDir(), stage.WorkDir(), nil)
            if err != nil {
                SchedulerLogger.Infof("Fail to merge shadow work directory %s to target %s: %s\n",
                    stage.ShadowWorkDir(), stage.WorkDir(), err.Error())
                return err
            }
        }
    } else {
        SchedulerLogger.Debugf("Do post work for fail stage %s\n",
            stage.GetID())
    }

    /*the success case have been handled before*/
    if !success && stage.ShadowOutputDir() != "" {
        err := storageMgr.DeleteDirOnScheduler(stage.ShadowOutputDir(), true)
        if err != nil {
            SchedulerLogger.Errorf("Fail to delete shadow output dir %s: %s\n",
                stage.ShadowOutputDir(), err.Error())
            /*ignore the error*/
        }
    }

    if !success && stage.ShadowWorkDir() != "" {
        err := storageMgr.DeleteDirOnScheduler(stage.ShadowWorkDir(), true)
        if err != nil {
            SchedulerLogger.Errorf("Fail to delete shadow work dir %s: %s\n",
                stage.ShadowWorkDir(), err.Error())
            /*ignore the error*/
        }
    }


    stage.ClearShadowDir()

    /* Tag the output file of the stage with the files it origins from. This is
     * for data management to trace the origin of a file.
     */
    if success {
        job := stage.Job()
        outputFileMap := stage.GetTargetOutputs()
        if outputFileMap != nil {
            for _, outputFile := range outputFileMap {
                stageTagInfo := &StageTagInfo{
                    JobId: job.GetID(),
                    PipelineName: stage.PipelineName(),
                    PipelineVersion: stage.PipelineVersion(),
                    StageName: stage.Name(),
                }
                err := GetStorageMgr().SetFileOriginFromTag(outputFile, stage.GetInputFileList(), stageTagInfo)
                if err != nil {
                    SchedulerLogger.Errorf("Fail to tag the file %s with origin file list: %s\n",
                        outputFile, err.Error())
                }
            }
        }
    }

    /*
     * Clear the tracked input file list to save memory. 
     * It will not be used anymore.
     */
    stage.ClearInputFileList()

    return nil
}

/*
 * Build the execCommand with correct input/output/variable assignment.
 * It parses the cmd and assign each placeholder with correct value. The
 * volumes required are also collected during this process.
 */
func (stage *blCmdStage) BuildCommand() *BuildStageErrorInfo {
    cmdStr := stage.Cmd()
    buildCommand := ""

    parser := NewBLParser()
    if cmdStr != "" {
        buildStr := ""
        buildStageErrInfo := parser.TranslatePlaceHolders(cmdStr,
                func(stmt BLStatement) (error, bool) {
                    var err error
                    builtStmt := ""
                    stmtType := stmt.StmtType()
                    stmtPrefix := stmt.Prefix()
                    stmtValue := stmt.Value()
                    if stmtType.IsStr() {
                        buildStr += stmtValue
                    } else if stmtType.IsExpandInput() {
                        /*
                         * If $inputs specified, use the last stage's output
                         * use $inputs.GB_TAG_LAST_OUTPUT
                         */
                        if stmtValue == "" {
                            stmtValue = GB_TAG_LAST_OUTPUT
                        }
                        err, builtStmt = stage.BuildAllNodeInput(stmtPrefix,
                            stmtValue)
                        if err != nil {
                            /*use input file list if have*/
                            if stmtValue == GB_TAG_LAST_OUTPUT {
                                err, builtStmt = stage.BuildAllFileInput(stmtPrefix)
                            }
                            if err != nil {
                                SchedulerLogger.Errorf("Build all nodes input or files on %s/%s failure:%s",
                                    stmtPrefix, stmtValue, err.Error())
                                return err, false
                            }
                        }
                        buildStr += builtStmt
                    } else if stmtType.IsExpandFile() {
                        err, builtStmt = stage.BuildAllFileInput(stmtPrefix)
                        if err != nil {
                            return err, false
                        }
                        buildStr += builtStmt
                    } else if stmtType.IsIndexFile() {
                        err, builtStmt = stage.BuildIndexedFileInput(stmtPrefix,
                            stmt.Index() - 1)
                        if err != nil {
                            return err, false
                        }
                        buildStr += builtStmt
                    } else if stmtType.IsTagInput() {
                        /*
                         * If $input specified, use the last stage's output
                         * use $input.GB_TAG_LAST_OUTPUT
                         */
                        if stmtValue == "" {
                            stmtValue = GB_TAG_LAST_OUTPUT
                        }
                        err, builtStmt = stage.BuildNodeInputFile(stmtValue)
                        if err != nil {
                            if stmtValue == GB_TAG_LAST_OUTPUT {
                                err, builtStmt = stage.BuildIndexedFileInput("",
                                    0)
                            }
                            if err != nil {
                                return err, false
                            }
                        }
                        buildStr += stmtPrefix + builtStmt 
                    } else if stmtType.IsTagIndexInput() {
                        /*
                         * translate input1.tag, input2.tag, ... like
                         * place holders. The index should be minus 1 to adapt
                         * to go arry index
                         */
                        if stmtValue == "" {
                            /*
                             * If $inputNum specified, use the last stage's output
                             * use $inputNum.GB_TAG_LAST_OUTPUT
                             */
                            stmtValue = GB_TAG_LAST_OUTPUT
                        }
                        err, builtStmt = stage.BuildNodeIndexedInput(stmtValue,
                            stmt.Index() - 1)
                        if err != nil {
                            if stmtValue == GB_TAG_LAST_OUTPUT {
                                err, builtStmt = stage.BuildIndexedFileInput("",
                                    stmt.Index() - 1)
                            }
                            if err != nil {
                                SchedulerLogger.Errorf("Build indexed input or file on %s failure:%s",
                                    stmtValue, err.Error())
                                return err, false
                            }
                        }
                        buildStr += stmtPrefix + builtStmt 
                    } else if stmtType.IsTagInputDir() {
                        err, builtStmt = stage.BuildNodeInputDir(stmtValue)
                        if err != nil {
                            return err, false
                        }
                        buildStr += stmtPrefix + builtStmt
                    } else if stmtType.IsTagRef() {
                        err, builtStmt = stage.BuildTagFile(stmtValue)
                        if err != nil {
                            return err, false
                        }
                        buildStr += stmtPrefix + builtStmt
                    } else if stmtType.IsTagVariable() {
                        err, builtStmt = stage.BuildTagVariable(stmtValue)
                        if err != nil {
                            SchedulerLogger.Errorf("Fail to parse tag variable: %s",
                                err.Error())
                            return err, false
                        }
                        buildStr += stmtPrefix + builtStmt
                    } else if stmtType.IsTagBranch() {
                        err, builtStmt = stage.BuildBranchVariable(stmtValue)
                        if err != nil {
                            return err, false
                        }
                        buildStr += stmtPrefix + builtStmt
                    } else if stmtType.IsTagOutput() {
                        err, outputStr := stage.GetOutput(stmtValue, false)
                        if err != nil {
                            return err, false
                        }
                        buildStr += stmtPrefix + outputStr
                    } else if stmtType.IsTagOutputPath() {
                        err, outputStr := stage.GetOutput(stmtValue, true)
                        if err != nil {
                            return err, false
                        }
                        buildStr += stmtPrefix + outputStr
                    } else if stmtType.IsSysDir() {
                        if strings.ToUpper(stmtValue) == BL_KW_SYSWORKDIR {
                            buildStr += stmtPrefix + stage.BuildWorkDir()
                        } else if strings.ToUpper(stmtValue) == BL_KW_SYSINPUTDIR {
                            buildStr += stmtPrefix + stage.BuildInputDir()
                        } else if strings.ToUpper(stmtValue) == BL_KW_SYSJOBWORKDIR {
                            buildStr += stmtPrefix + stage.MapDataPathToContainer(stage.Job().WorkDir())
                        } else if strings.ToUpper(stmtValue) == BL_KW_SPARKMASTER {
                            buildStr += stmtPrefix + GetSparkCluster()
                        } else {
                            SchedulerLogger.Errorf("Can't build sys dir %s\n",
                                stmtValue)
                            return errors.New("Unsupported sys tag " + stmtValue),
                                false
                        }
                    } else if stmtType.IsOutputDir() {
                        err, outputDirStr := stage.GetOutputDir(stmtValue, true)
                        if err != nil {
                            return err, false
                        }
                        buildStr += stmtPrefix + outputDirStr
                    } else if stmtType.IsOutputDirPath() {
                        err, outputDirStr := stage.GetOutputDir(stmtValue, false)
                        if err != nil {
                            return err, false
                        }
                        buildStr += stmtPrefix + outputDirStr
                    }

                    return nil, true
            })
        if buildStageErrInfo.Err != nil {
            SchedulerLogger.Errorf("Build command failure %s\n",
                buildStageErrInfo.Err.Error())
            buildStageErrInfo.ItemName = stage.Name()
            buildStageErrInfo.ItemCmdStr = cmdStr
            buildStageErrInfo.IsCMDErr = true
            buildStageErrInfo.ErrInfo = fmt.Sprintf("Build command: %s", buildStageErrInfo.Err.Error())
            return buildStageErrInfo
        } else {
            if buildCommand == "" {
                buildCommand = buildStr
            } else {
                buildCommand += " " + buildStr + " "
            }
        }
    }

    stage.SetCommand(buildCommand)
    return nil
}

func (stage *blCmdStage) _GetPrefixedTag(tag string) string {
    prefix := stage.tagPrefix
    if stage.tagPrefixMap != nil {
        if value, ok := stage.tagPrefixMap[tag]; ok {
            prefix = value
        }
    }

    if prefix == "" {
        return ""
    } else {
        return prefix + "-" + tag
    }
}

/*A stage may have many output tags and outputDir tags*/
func (stage *blCmdStage) GetOutputTags() ([]string, []string) {
    rawOutputTags, rawOutputDirTags := stage._GetOutputTags()

    /*Add the prefixed tag automatically*/
    var outputTags []string
    var outputDirTags []string
    for _, tag := range rawOutputTags {
        outputTags = append(outputTags, tag)
        if prefixedTag := stage._GetPrefixedTag(tag); prefixedTag != "" {
            outputTags = append(outputTags, prefixedTag)
        }
    }

    for _, tag := range rawOutputDirTags {
        outputDirTags = append(outputDirTags, tag)
        if prefixedTag := stage._GetPrefixedTag(tag); prefixedTag != "" {
            outputDirTags = append(outputDirTags, prefixedTag)
        }
    }

    return outputTags, outputDirTags
}

func (stage *blCmdStage) _GetOutputTags() ([]string, []string) {
    cmdStr := stage.Cmd()

    var outputTags []string = nil
    var outputDirTags []string = nil
    parser := NewBLParser()
    if cmdStr != "" {
        buildStageErrInfo := parser.TranslatePlaceHolders(cmdStr,
                func(stmt BLStatement) (error, bool) {
                        if stmt.StmtType().IsTagOutput() {
                            outputTags = append(outputTags, stmt.Value())
                        }
                        if stmt.StmtType().IsOutputDir() {
                            outputDirTags = append(outputDirTags, stmt.Value())
                        }
                        return nil, true
            })
        if buildStageErrInfo.Err != nil {
            SchedulerLogger.Errorf("Can't parse output tag %s\n",
                buildStageErrInfo.Err.Error())
            buildStageErrInfo.ItemName = stage.Name()
            buildStageErrInfo.ItemCmdStr = cmdStr
            buildStageErrInfo.IsCMDErr = true
            buildStageErrInfo.ErrInfo = fmt.Sprintf("Build command: %s", buildStageErrInfo.Err.Error())
            return nil, nil
        } else {
            return outputTags, outputDirTags
        }
    }

    return nil, nil
}

func (stage *blCmdStage)ToBioflowStageInfo() *BioflowStageInfo{
    stageInfo := &BioflowStageInfo {
        Id: stage.GetID(),
        Name: stage.Name(),
        State: StageStateToStr(stage.State()),
        Command: stage.GetCommand(),
        Output: stage.GetTargetOutputs(),
        BackendId: "N/A",
        TaskId: "N/A",
        ScheduleTime: stage.ScheduledTime().Format(time.UnixDate),
        SubmitTime: stage.SubmitTime().Format(time.UnixDate),
        FinishTime: stage.FinishTime().Format(time.UnixDate),
        TotalDuration: stage.TotalDuration(),
        RetryCount: stage.RetryCount(),
        CPU: stage.GetCPU(),
        Memory: stage.GetMemory(),
        GPU: stage.GetGPU(),
        GPUMemory: stage.GetGPUMemory(),
        Disk: stage.GetDisk(),
        ServerType: stage.GetServerType(),
        ExecMode: stage.ExecMode(),
        HostName: stage.HostName(),
        HostIP: stage.IP(),
    }

    switch stage.State() {
        case STAGE_INITIAL:
            stageInfo.SubmitTime = "N/A"
            stageInfo.ScheduleTime = "N/A"
            stageInfo.FinishTime = "N/A"
            stageInfo.TotalDuration = -1
        case STAGE_SUBMITTED, STAGE_QUEUED:
            stageInfo.ScheduleTime = "N/A"
            stageInfo.FinishTime = "N/A"
            stageInfo.TotalDuration = -1
        case STAGE_RUNNING:
            stageInfo.FinishTime = "N/A"
            stageInfo.TotalDuration = -1
    }

    return stageInfo
}

/*
 * Restore the stage execution stage from JSON info stored in database.
 * Noted that consider the following complicated cases:
 * 1) because failure retry, so a stage may exist many times in the
 *    execution history. We need merge the information.
 * 2) the pending stage's JSON should have the latest execution information
 */
func (stage *blCmdStage)RestoreExecutionState(stageJsonInfo *StageJSONInfo,
    pending bool) error{
    /*Merge the retry count*/
    if stage.RetryCount() < stageJsonInfo.RetryCount {
        stage.SetRetryCount(stageJsonInfo.RetryCount)
    }

    /*
     * All the done stage execution information can be obtained directly
     * from the done stages history. so only need restore pending stages'
     * information.
     */
    if pending {
        submitTime, err := time.Parse(time.UnixDate,
            stageJsonInfo.SubmitTime)
        if err != nil {
            SchedulerLogger.Errorf("Fail restore stage's submit time %s: %s\n",
                stageJsonInfo.SubmitTime, err.Error())
        } else {
            stage.SetSubmitTime(submitTime)
        }

        scheduleTime, err := time.Parse(time.UnixDate,
            stageJsonInfo.ScheduledTime)
        if err != nil {
            SchedulerLogger.Errorf("Fail restore stage's schedule time %s: %s\n",
                stageJsonInfo.ScheduledTime, err.Error())
        } else {
            stage.SetScheduledTime(scheduleTime)
        }

        finishTime, err := time.Parse(time.UnixDate,
            stageJsonInfo.FinishTime)
        if err != nil {
            SchedulerLogger.Errorf("Fail restore stage's finish time %s: %s\n",
                stageJsonInfo.FinishTime, err.Error())
        } else {
            stage.SetFinishTime(finishTime)
        }

        /*restore the resource requirement*/
        rsc := ResourceSpec{}
        rsc.SetCPU(stageJsonInfo.CPU)
        rsc.SetMemory(stageJsonInfo.Memory)
        rsc.SetGPU(stageJsonInfo.GPU)
        rsc.SetGPUMemory(stageJsonInfo.GPUMemory)
        rsc.SetDisk(stageJsonInfo.Disk)
        rsc.SetServerType(stageJsonInfo.ServerType)
        stage.SetResourceSpec(rsc)

        if stageJsonInfo.HostName != "" {
            stage.SetHostName(stageJsonInfo.HostName)
        }
        if stageJsonInfo.HostIP != "" {
            stage.SetIP(stageJsonInfo.HostIP)
        }

        /*restore the stage execution info*/
        err, _, _ = stage.PrepareExecution(true)
        if err != nil {
            return err
        }
    }

    return nil
}

func (stage *blCmdStage)Cleanup() error{
    patterns := make([]string, 0)
    storageMgr := GetStorageMgr()
    parser := NewBLParser()
    outputDir := stage.WorkDir()
    if stage.OutputDir() != "" {
        outputDir = stage.OutputDir()
    }
    if stage.CleanupPattern() != "" {
        patternItems := parser.IdentifySeparatePatterns(stage.CleanupPattern())
        if len(patternItems) > 0 { 
            patterns = append(patterns, patternItems ...)
        }
        /*the cleanup will be done by scheduler, so translates
          the path relative to scheduler volumes mount*/
        err, workDir := storageMgr.MapPathToSchedulerVolumeMount(outputDir)
        if err != nil {
            SchedulerLogger.Errorf("Can't map directory to scheduler volumes:%s\n",
                err.Error())
            return err
        }
        err = FSUtilsDeleteFilesByPatterns(workDir, patterns)
        if err != nil {
            SchedulerLogger.Errorf("Fail to cleanup files for %s: %s\n",
                workDir, err.Error())
            return err
        }
    }

    return nil
}

func (stage *blCmdStage) FilesNeedPrepare() []string {
    buildStageErrInfo := stage.BuildDataDependence()
    if buildStageErrInfo != nil {
        return nil
    }
    files := stage.conVolMgr.FilesNeedPrepare()
    return files
}

func (stage *blCmdStage) BuildDataDependence() *BuildStageErrorInfo {
    cmdStr := stage.Cmd()
    if cmdStr == "" {
        return nil
    }
    parser := NewBLParser()
    buildStageErrInfo := parser.TranslatePlaceHolders(cmdStr,
        func(stmt BLStatement) (error, bool) {
            var err error
            stmtType := stmt.StmtType()
            stmtPrefix := stmt.Prefix()
            stmtValue := stmt.Value()
            if stmtType.IsExpandInput() {
                /*
                 * If $inputs specified, use the last stage's output
                 * use $inputs.GB_TAG_LAST_OUTPUT
                 */
                if stmtValue == "" {
                    stmtValue = GB_TAG_LAST_OUTPUT
                }
                err, _ = stage.BuildAllNodeInput(stmtPrefix,
                    stmtValue)
                if err != nil {
                    /*use input file list if have*/
                    if stmtValue == GB_TAG_LAST_OUTPUT {
                        err, _ = stage.BuildAllFileInput(stmtPrefix)
                    }
                    if err != nil {
                        SchedulerLogger.Errorf("Build all nodes input or files on %s/%s failure:%s",
                            stmtPrefix, stmtValue, err.Error())
                        return err, false
                    }
                }
            } else if stmtType.IsExpandFile() {
                err, _ = stage.BuildAllFileInput(stmtPrefix)
                if err != nil {
                    return err, false
                }
            } else if stmtType.IsIndexFile() {
                err, _ = stage.BuildIndexedFileInput(stmtPrefix,
                    stmt.Index() - 1)
                if err != nil {
                    return err, false
                }
            } else if stmtType.IsTagInput() {
                /*
                 * If $input specified, use the last stage's output
                 * use $input.GB_TAG_LAST_OUTPUT
                 */
                if stmtValue == "" {
                    stmtValue = GB_TAG_LAST_OUTPUT
                }
                err, _ = stage.BuildNodeInputFile(stmtValue)
                if err != nil {
                    if stmtValue == GB_TAG_LAST_OUTPUT {
                        err, _ = stage.BuildIndexedFileInput("",
                            0)
                    }
                    if err != nil {
                        return err, false
                    }
                }
            } else if stmtType.IsTagIndexInput() {
                /*
                 * translate input1.tag, input2.tag, ... like
                 * place holders. The index should be minus 1 to adapt
                 * to go arry index
                 */
                if stmtValue == "" {
                    /*
                     * If $inputNum specified, use the last stage's output
                     * use $inputNum.GB_TAG_LAST_OUTPUT
                     */
                    stmtValue = GB_TAG_LAST_OUTPUT
                }
                err, _ = stage.BuildNodeIndexedInput(stmtValue,
                    stmt.Index() - 1)
                if err != nil {
                    if stmtValue == GB_TAG_LAST_OUTPUT {
                        err, _ = stage.BuildIndexedFileInput("",
                            stmt.Index() - 1)
                    }
                    if err != nil {
                        SchedulerLogger.Errorf("Build indexed input or file on %s failure:%s",
                            stmtValue, err.Error())
                        return err, false
                    }
                }
            } else if stmtType.IsTagRef() {
                err, _ = stage.BuildTagFile(stmtValue)
                if err != nil {
                    return err, false
                }
            } else if stmtType.IsTagVariable() {
                err, _ = stage.BuildTagVariable(stmtValue)
                if err != nil {
                    SchedulerLogger.Errorf("Fail to parse tag variable: %s",
                        err.Error())
                    return err, false
                }
            } else if stmtType.IsTagBranch() {
                err, _ = stage.BuildBranchVariable(stmtValue)
                if err != nil {
                    return err, false
                }
            }

            return nil, true
        })

    if buildStageErrInfo.Err != nil {
        SchedulerLogger.Errorf("Build command failure %s\n",
            buildStageErrInfo.Err.Error())
        buildStageErrInfo.ItemName = stage.Name()
        buildStageErrInfo.ItemCmdStr = cmdStr
        buildStageErrInfo.IsCMDErr = true
        buildStageErrInfo.ErrInfo = fmt.Sprintf("Build command: %s", buildStageErrInfo.Err.Error())
        return buildStageErrInfo
    }else {
        return nil
    }
}

/*
 * Return all the shadow directories and files may be wrote by these stage.
 * this is used to ask storage to help cache these files proactively.
 */
func (stage *blCmdStage)_GetShadowOutputDirsAndFiles() ([]string, []string) {
    /*
     * Build the files or dirs map. This only cost once.
     */
    stage._BuildOutputDirsMap(true)
    stage._BuildOutputFilesMap(true)

    /*Now the shadow output dirs and files map must be ready*/
    var outputDirs []string = nil
    for _, dir := range stage.shadowOutputDirsMap {
        outputDirs = append(outputDirs, dir)
    }
    var outputFiles []string = nil
    for _, file := range stage.shadowOutputFilesMap {
        outputFiles = append(outputFiles, file)
    }

    return outputDirs, outputFiles
}
