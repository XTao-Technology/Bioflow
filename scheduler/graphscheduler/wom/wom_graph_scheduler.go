/* 
 Copyright (c) 2018 XTAO technology <www.xtaotech.com>
 All rights reserved.

 Redistribution and use in source and binary forms, with or without
 modification, are permitted provided that the following conditions
 are met:
  1. Redistributions of source code must retain the above copyright
     notice, this list of conditions and the following disclaimer.
  2. Redistributions in binary form must reproduce the above copyright
     notice, this list of conditions and the following disclaimer in the
     documentation and/or other materials provided with the distribution.
 
  THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS'' AND
  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
  ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE
  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
  OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
  HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
  LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
  OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
  SUCH DAMAGE.
*/
package wom

import (
    "strings"
    "errors"
    "strconv"
    "sync"
    . "github.com/xtao/bioflow/message"
    . "github.com/xtao/bioflow/common"
    . "github.com/xtao/bioflow/storage"
    . "github.com/xtao/bioflow/scheduler/common"
    "github.com/xtao/dsl-go/engine"
    womtype "github.com/xtao/dsl-go/wom/types"
    "github.com/xtao/dsl-go/wom"
)

type ExecUnitInfo struct {
    stage *womCmdStage
    unit *engine.ExecutableUnit
    ctxt *wom.WomExecContext
}

/*
 * Scheduler for WDL or CWL. It is responsible for triggering
 * build and execute the graph generated by WDL or CWL pipeline.
 */
type womGraphScheduler struct {
    /*Wom Graph build state*/
    buildCompleted bool
    womEngine *engine.VMEngine

    /*stage map*/
	lock sync.Mutex
    execUnits map[string]*ExecUnitInfo
    needRetryUnits map[string]*ExecUnitInfo
    forbiddenUnits map[string]*ExecUnitInfo
    recoveredStages map[string]Stage

    /*
     * Hold the context information for the graph builder
     */
    job Job
    pipeline Pipeline
}


func (womScheduler *womGraphScheduler) GetStageByID(stageId string) Stage {
    womScheduler.lock.Lock()
    defer womScheduler.lock.Unlock()

    if unitInfo, found := womScheduler.execUnits[stageId]; found {
        return unitInfo.stage
    } else {
        if unitInfo, found := womScheduler.needRetryUnits[stageId]; found {
            return unitInfo.stage
        }
    }

    return nil
}

type ExecUnitState int
const (
    EXEC_UNIT_RETRY ExecUnitState = 1
    EXEC_UNIT_READY ExecUnitState = 2
    EXEC_UNIT_FORBIDDEN ExecUnitState = 3
    EXEC_UNIT_DONE ExecUnitState = 4
)

func (womScheduler *womGraphScheduler)ChangeExecUnitState(stageId string,
    state ExecUnitState) {
    womScheduler.lock.Lock()
    defer womScheduler.lock.Unlock()

    unitInfo, found := womScheduler.execUnits[stageId]
    if found {
        delete(womScheduler.execUnits, stageId)
        switch state {
            case EXEC_UNIT_RETRY:
                womScheduler.needRetryUnits[stageId] = unitInfo
            case EXEC_UNIT_FORBIDDEN:
                womScheduler.forbiddenUnits[stageId] = unitInfo
            case EXEC_UNIT_DONE:
        }
    }
}

func (womScheduler *womGraphScheduler)FindExecUnit(stageId string) *ExecUnitInfo {
    womScheduler.lock.Lock()
    defer womScheduler.lock.Unlock()

    return womScheduler.execUnits[stageId]
}

/*
 * The Wdl IO library will be executed on scheduler, so should map the path to
 * scheduler when coerce the File value to a string
 */
func WdlIOLibraryCoercer(womValue womtype.WomValue) string {
    if womValue == nil {
        return ""
    }
    switch womValue.(type) {
        case *womtype.WomFile:
            err, mappedPath := GetStorageMgr().MapPathToSchedulerVolumeMount(womValue.String())
            if err != nil {
                SchedulerLogger.Errorf("Fail to map data path on scheduler for wom file %s: %s\n",
                    womValue.String(), err.Error())
                return womValue.String()
            }
            return mappedPath
        default:
            return womValue.String()
    }
}

/*The function used to process the file path when building wdl commands*/
func WdlCommandFileCoercer(womValue womtype.WomValue,
    ctxt wom.CommandCoerceCtxt, job Job)(string, wom.CommandCoerceCtxt) {
    if womValue == nil {
        return "", ctxt
    }

    SchedulerLogger.Debugf("WdlCommandFileCoercer: tune value %s \n",
        womValue.String())

    var conVolMgr *ContainerVolMgr = nil
    if ctxt == nil {
        dataDir, _, _ := GetStorageMgr().GetContainerExecDir()
        conVolMgr = NewContainerVolMgr(dataDir, job.DataDir())
    } else {
        conVolMgr = ctxt.(*ContainerVolMgr)
    }

    switch womValue.(type) {
        case *womtype.WomFile:
            if FSUtilsIsFileURI(womValue.String()) {
                err, mappedPath := conVolMgr.MapDataPathToContainer("", womValue.String())
                if err != nil {
                    SchedulerLogger.Errorf("Fail to map data path for wom file %s: %s\n",
                        womValue.String(), err.Error())
                    return womValue.String(), conVolMgr
                }
                return mappedPath, conVolMgr
            } else {
                return womValue.String(), conVolMgr
            }
        default:
            return womValue.String(), conVolMgr
    }
}

/*
 * This function is used by WDL engine to decide whether it is a absolute
 * path. This is required because bioflow introduce the uniform file path
 * representation.
 */
func WdlFilePathChecker(filePath string)(wom.WomFilePathType, error) {
    err, _, vol, file := FSUtilsParseFileURI(filePath)
    if err == nil && file != "" && vol != "" {
        return wom.WOM_FILE_PATH_ABS, nil
    }

    if strings.HasPrefix(filePath, "/") {
        return wom.WOM_FILE_PATH_ABS, nil
    }
    return wom.WOM_FILE_PATH_REL, nil
}

/* Build wom graph and init wom graph executor*/
func (womScheduler *womGraphScheduler) BuildGraph() (error, *BuildStageErrorInfo) {
    if womScheduler.womEngine == nil {
        /*Init and load*/
        job := womScheduler.job
        sourceInfo := womScheduler.pipeline.SourceInfo()
        if sourceInfo.StoreDir == "" || sourceInfo.WorkflowFile == "" {
            return errors.New("No source info or workflow file for pipeline"), nil
        }
        wdlFile := sourceInfo.StoreDir + "/" + sourceInfo.WorkflowFile
        err, mappedWdlFile := GetStorageMgr().MapPathToSchedulerVolumeMount(wdlFile)
        if err != nil {
            SchedulerLogger.Errorf("Fail to map job %s wdl file %s: %s\n",
                job.GetID(), wdlFile, err.Error())
            return err, nil
        }
        err, mappedWorkdir := GetStorageMgr().MapPathToSchedulerVolumeMount(job.WorkDir())
        if err != nil {
            SchedulerLogger.Errorf("Fail to map job %s workdir %s: %s\n",
                job.GetID(), job.WorkDir(), err.Error())
            return err, nil
        }

        inputJson := job.InputDataSet().WorkflowInput()
        womEngine := engine.NewVMEngine(mappedWorkdir)
        err = womEngine.Init()
        if err != nil {
            SchedulerLogger.Errorf("Fail to init the wom VM engine: %s\n",
                err.Error())
            return err, nil
        }

        tmpIODir := job.WorkDir() + "/WomInternalIOFiles"
        mappedTmpIODir := mappedWorkdir + "/WomInternalIOFiles"
        err = FSUtilsMkdir(mappedTmpIODir, true)
        if err != nil {
            SchedulerLogger.Errorf("Fail to create the internal io directory %s for wom engine: %s\n",
                mappedTmpIODir, err.Error())
            return err, nil
        }

        /*configure the external io library for wom engine*/
        plugLib := engine.NewExPlugIOLibrary(func (womValue womtype.WomValue,
            ctxt wom.CommandCoerceCtxt)(string, wom.CommandCoerceCtxt) {
                return WdlCommandFileCoercer(womValue, ctxt, job)
            },
            WdlIOLibraryCoercer,
            nil, func(id string) string {
                /*noted that we should use the relative directory here*/
                return tmpIODir
            })
        plugLib.SetPathChecker(WdlFilePathChecker)
        womEngine.SetPlugIOLib(plugLib)

        if err := womEngine.LoadFromJSON(mappedWdlFile, inputJson); err != nil {
            return err, nil
        }
        womScheduler.womEngine = womEngine
    }

    return nil, nil
}

func (womScheduler *womGraphScheduler) GetGraphInfo() (error, FlowGraphInfo){
    info := NewWomFlowGraphInfo()
    info.Completed = true
    return nil, info
}

func (womScheduler *womGraphScheduler) RestoreGraph(info FlowGraphInfo) (error, bool, *BuildStageErrorInfo) {
    stages, _, err := womScheduler._ScheduleGraph()
    womScheduler.recoveredStages = stages
    return err, true, nil
}

/*
 * Whether job's flow graph is built complete
 */
func (womScheduler *womGraphScheduler) GraphCompleted() bool {
    return true
}

const (
    WOM_RUNTIME_KEY_DOCKER string = "DOCKER"
    WOM_RUNTIME_KEY_CPU string = "CPU"
    WOM_RUNTIME_KEY_MEMORY string = "MEMORY"
    WOM_RUNTIME_KEY_DISK string = "DISKS"
    WOM_RUNTIME_KEY_GPU string = "GPU"
    WOM_RUNTIME_KEY_GPU_MEMORY string = "GPUMEMORY"
    WOM_RUNTIME_KEY_SERVERTYPE string = "SERVERTYPE"
    WOM_RUNTIME_KEY_RETRY string = "RETRY"
    WOM_RUNTIME_KEY_SPARKEXECUTORURI string = "SPARKEXECUTORURI"
    WOM_RUNTIME_KEY_USEXTAOSCHEDULER string = "USEXTAOSCHEDULER"
    WOM_RUNTIME_KEY_USEXTAOSPARKSCHEDULER string = "USEXTAOSPARKSCHEDULER"
    WOM_RUNTIME_KEY_SLAVECONSTRAINTS string = "SLAVECONSTRAINTS"
    WOM_RUNTIME_KEY_VOLUMES string = "VOLUMES"
    WOM_RUNTIME_KEY_IOPATTERN string = "IOPATTERN"
    WOM_RUNTIME_KEY_RWPATTERN string = "RWPATTERN"
    WOM_RUNTIME_KEY_WORKINGSET string = "WORKINGSET"
    WOM_RUNTIME_KEY_ISOLEVEL string = "ISOLATIONLEVEL"
    WOM_RUNTIME_KEY_LSFILES string = "LARGESMALLFILES"
    WOM_RUNTIME_KEY_EPHLEVEL string = "EPHEREMALLEVEL"
    WOM_RUNTIME_KEY_EPHPATTERN string = "EPHEREMALFILEPATTERN"
    WOM_RUNTIME_KEY_EPHMAP string = "EPHEREMALMAP"
)

/*
 * The memory format for WDL spec:
 *   1) Int - Intepreted as bytes
 *   2) String - This should be a decimal value with suffixes like B, KB, MB or binary
 *      suffixes KiB, MiB. For example: 6.2 GB, 5MB, 2GiB.
 */
func ParseWDLMemorySpecToMB(strMem string) (float64, error) {
    units := []string{"K", "M", "G", "KI", "MI", "GI"}
    ratios := []float64{1000, 1000 * 1000, 1000 * 1000 * 1000,
        1024, 1024 * 1024, 1024 * 1024 * 1024}
    strValue := strings.TrimSuffix(strings.ToUpper(strMem), "B")
    var ratio float64 = 1
    /*The ratios should be calculated as binary presentation by default*/
    ratioIndex := 6
    for index, unit := range units {
        if strings.HasSuffix(strValue, unit) {
            strValue = strings.TrimSuffix(strValue, unit)
            ratio = ratios[index]
            ratioIndex = index
            break
        }
    }

    /* Calculate the ratio beween M and Byte by considering the
     * the unit:
     * 1) MiB = 1024 * 1024 B
     * 2) MB = 1000 * 1000 B
     */
    var mbSize float64 = 1000 * 1000
    if ratioIndex >= 3 {
        mbSize = 1024 * 1024
    }
    strValue = strings.TrimSpace(strValue)
    if f, err := strconv.ParseFloat(strValue, 64); err == nil {
        memory := f * ratio / mbSize
        return memory, nil
    } else {
        return 3000.0, err
    }
}

func HandleRuntimeAttributes(stage *womCmdStage, attrs map[string]womtype.WomValue) error {
    var cpu  float64 = 1.0
    var memory float64 = 3000.0
    var disk float64 = 0
    var serverType string = ""
    var gpu float64 = 0
    var gpuMemory float64 = 0
    ioAttr := &IOAttr{}
    hasIoAttr := false
    envVars := make(map[string]string)
    for key, womValue := range attrs {
        switch strings.ToUpper(key) {
            case WOM_RUNTIME_KEY_DOCKER:
                stage.SetImage(womValue.String())
            case WOM_RUNTIME_KEY_CPU:
                if f, err := strconv.ParseFloat(womValue.String(), 64); err == nil {
                    cpu = f
                } else {
                    SchedulerLogger.Errorf("The cpu value %s parse failure: %s\n",
                        womValue.String(), err.Error())
                }
            case WOM_RUNTIME_KEY_MEMORY:
                if f, err := ParseWDLMemorySpecToMB(womValue.String()); err == nil {
                    memory = f
                } else {
                    SchedulerLogger.Errorf("HandleWDLRuntimeAttrs: memory value %s parse failure: %s\n",
                        womValue.String(), err.Error())
                }
            case WOM_RUNTIME_KEY_DISK:
                /*Handle disk and memory in the same way*/
                if f, err := ParseWDLMemorySpecToMB(womValue.String()); err == nil {
                    disk = f
                } else {
                    SchedulerLogger.Errorf("HandleWDLRuntimeAttrs: disk value %s parse failure: %s\n",
                        womValue.String(), err.Error())
                }
            case WOM_RUNTIME_KEY_RETRY:
                if retry, err := strconv.ParseInt(womValue.String(), 10, 32); err == nil {
                    stage.SetFailRetryLimit(int(retry))
                } else {
                    SchedulerLogger.Errorf("The retry value %s parse failure: %s\n",
                        womValue.String(), err.Error())
                }
            case WOM_RUNTIME_KEY_GPU:
                if intVal, err := strconv.ParseFloat(womValue.String(), 64); err == nil {
                    gpu = intVal
                } else {
                    SchedulerLogger.Errorf("The gpu value %s parse failure: %s\n",
                        womValue.String(), err.Error())
                }
            case WOM_RUNTIME_KEY_GPU_MEMORY:
                if floatVal, err := strconv.ParseFloat(womValue.String(), 64); err == nil {
                    gpuMemory = floatVal
                } else {
                    SchedulerLogger.Errorf("The gpu memory value %s parse failure: %s\n",
                        womValue.String(), err.Error())
                }
            case WOM_RUNTIME_KEY_SPARKEXECUTORURI:
                envVars["SPARK_EXECUTOR_URI"] = womValue.String()
            case WOM_RUNTIME_KEY_SERVERTYPE:
                serverType = womValue.String()
            case WOM_RUNTIME_KEY_USEXTAOSCHEDULER:
                if boolVal, err := strconv.ParseBool(womValue.String()); err == nil {
                    if boolVal {
                        envVars["XTAO_MESOS"] = ServiceManifestGetMesosMaster()
                    }
                } else {
                    SchedulerLogger.Errorf("The usextaoscheduler value %s parse failure: %s\n",
                        womValue.String(), err.Error())
                }
            case WOM_RUNTIME_KEY_USEXTAOSPARKSCHEDULER:
                if boolVal, err := strconv.ParseBool(womValue.String()); err == nil {
                    if boolVal {
                        envVars["SPARK_MASTER_URI"] = GetSparkCluster()
                    }
                } else {
                    SchedulerLogger.Errorf("The usextaosparkscheduler value %s parse failure: %s\n",
                        womValue.String(), err.Error())
                }
            case WOM_RUNTIME_KEY_SLAVECONSTRAINTS:
                constraints := make(map[string]string)
                if values, isMap := womValue.(*womtype.WomMapValue); isMap {
                    for k, v := range values.Map() {
                        constraints[k.String()] = v.String()
                    }
                    stage.AddConstraints(constraints)
                } else {
                    SchedulerLogger.Errorf("The slaveconstraints value %s parse failure: %s\n",
                        womValue.String(), "Values must be map")
                }
            case WOM_RUNTIME_KEY_VOLUMES:
                volumes := make(map[string]string)
                if values, isMap := womValue.(*womtype.WomMapValue); isMap {
                    for k, v := range values.Map() {
                        volumes[k.String()] = v.String()
                    }
                    stage.SetVolumes(volumes)
                } else {
                    SchedulerLogger.Errorf("The volumes value %s parse failure: %s\n",
                        womValue.String(), "Values must be map")
                }

            /*
             * Parse and handle the user specified io attributes. These attributes are defined
             * in the user message.
             */
            case WOM_RUNTIME_KEY_IOPATTERN:
                hasIoAttr = true
                ioAttr.SetIOPattern(womValue.String())
            case WOM_RUNTIME_KEY_RWPATTERN:
                hasIoAttr = true
                ioAttr.SetRWPattern(womValue.String())
            case WOM_RUNTIME_KEY_WORKINGSET:
                hasIoAttr = true
                ioAttr.SetWorkingSet(womValue.String())
            case WOM_RUNTIME_KEY_ISOLEVEL:
                hasIoAttr = true
                ioAttr.SetIsoLevel(womValue.String())
            case WOM_RUNTIME_KEY_EPHLEVEL:
                hasIoAttr = true
                ioAttr.SetEphLevel(womValue.String())
            case WOM_RUNTIME_KEY_EPHPATTERN:
                hasIoAttr = true
                ioAttr.SetEphPattern(womValue.String())
            case WOM_RUNTIME_KEY_EPHMAP:
                ephMap := make(map[string]string)
                if values, isMap := womValue.(*womtype.WomMapValue); isMap {
                    for k, v := range values.Map() {
                        ephMap[k.String()] = v.String()
                    }
                    hasIoAttr = true
                    ioAttr.SetEphMap(ephMap)
                } else {
                    SchedulerLogger.Errorf("The EpheremalMap value %s parse failure: %s\n",
                        womValue.String(), "Values must be map")
                }
            case WOM_RUNTIME_KEY_LSFILES:
                if bValue, isBool := womValue.(*womtype.WomBooleanValue); isBool {
                    ioAttr.SetLargeSmallFiles(bValue.Boolean())
                    hasIoAttr = true
                } else {
                    SchedulerLogger.Errorf("The LargeSmallFiles value %s parse failure: %s\n",
                        womValue.String(), "Values must be boolean")
                }
            default:
                SchedulerLogger.Warnf("Un-supported runtime attributes %s:%s\n",
                    key, womValue.String())
        }
    }

    resource := ResourceSpec{}
    resource.SetCPU(cpu)
    resource.SetMemory(memory)
    resource.SetDisk(disk)
    resource.SetGPU(gpu)
    resource.SetGPUMemory(gpuMemory)
    resource.SetServerType(serverType)
    stage.SetResourceSpec(resource)
    stage.SetEnv(envVars)
    if hasIoAttr {
        stage.SetIOAttr(ioAttr)
    }

    return nil
}

func (womScheduler *womGraphScheduler) CheckGraphState() int {
    job := womScheduler.job
    state, err := womScheduler.womEngine.CheckWomGraphState()
    if err != nil {
        SchedulerLogger.Errorf("Check job %s wom graph failure: %s\n",
            job.GetID(), err.Error())
        return JOB_GRAPH_ERROR
    }
    
    return womScheduler._EvaluateGraphState(state)
}

func (womScheduler *womGraphScheduler)RecoveredStages() map[string]Stage {
    womScheduler.lock.Lock()
    defer womScheduler.lock.Unlock()

    if len(womScheduler.recoveredStages) > 0 {
        stages := womScheduler.recoveredStages
        womScheduler.recoveredStages = nil
        return stages
    }

    return nil
}

func (womScheduler *womGraphScheduler)ClearRecoveredStage(stageId string) {
    womScheduler.lock.Lock()
    defer womScheduler.lock.Unlock()

    if womScheduler.recoveredStages != nil {
        if _, found := womScheduler.recoveredStages[stageId]; found {
            delete(womScheduler.recoveredStages, stageId)
            SchedulerLogger.Infof("The stage %s deleted from recovered list of Wom Graph Scheduler\n",
                stageId)
        }
    }
}

func (womScheduler *womGraphScheduler)Schedule() (map[string]Stage, int, error) {
    return womScheduler._ScheduleGraph()
}

func (womScheduler *womGraphScheduler)_EvaluateGraphState(state engine.GraphState) int {
    womScheduler.lock.Lock()
    defer womScheduler.lock.Unlock()

    switch state {
        case engine.GRAPH_STATE_DONE:
            if len(womScheduler.execUnits) == 0 &&
                len(womScheduler.needRetryUnits) == 0 {
                if len(womScheduler.forbiddenUnits) > 0 {
                    return JOB_GRAPH_PSEUDO_FINISH
                } else {
                    return JOB_GRAPH_FINISHED
                }
            }
        case engine.GRAPH_STATE_PENDING:
            if len(womScheduler.execUnits) == 0 &&
                len(womScheduler.needRetryUnits) == 0 {
                if len(womScheduler.forbiddenUnits) > 0 {
                    return JOB_GRAPH_PSEUDO_FINISH
                }
            }
    }

    return JOB_GRAPH_PENDING
}
    
func (womScheduler *womGraphScheduler) _ScheduleGraph() (map[string]Stage, int, error) {
    job := womScheduler.job

    SchedulerLogger.Debugf("Start schedule wom graph of job %s\n",
        job.GetID())
    /*
     * Need reschedule to handle the graph processed events. This help drives
     * the expression wom node evaluation
     */
retrySchedule:
    execUnits, state, err := womScheduler.womEngine.FindPendingExecUnits()
    if err != nil {
        SchedulerLogger.Errorf("Fail to schedule wom engine: %s\n",
            err.Error())
        return nil, JOB_GRAPH_ERROR, err
    }

    issuedStages := make(map[string]Stage)
    for _, execUnit := range execUnits {
        /*Issue a wom stage to execute the executable unit of Wom Graph*/
        execCmd := execUnit.Command()
        var volMgr *ContainerVolMgr = nil
        if ctxt := execUnit.CommandCoerceCtxt(); ctxt != nil {
            volMgr = ctxt.(*ContainerVolMgr)
        }
        stageName := execUnit.Node().FullyQualifiedName()
        stageId := execUnit.ID()
        workDir := job.WorkDir() + "/" + stageId
        logDir := job.LogDir()
        womStage := NewWomCmdStage(job, stageId, execCmd, workDir, logDir,
            volMgr, job.DataDir())
        womStage.SetName(stageName)
        /*Set the stdout and stderr files here*/ 
        err, mappedWorkdir := GetStorageMgr().MapPathToSchedulerVolumeMount(workDir)
        if err != nil {
            SchedulerLogger.Errorf("Fail to map stage's workdir %s: %s\n",
                workDir, err.Error())
            return nil, JOB_GRAPH_ERROR, err
        }
        execUnit.SetStdoutFile(mappedWorkdir + "/stdout")
        execUnit.SetStderrFile(mappedWorkdir + "/stderr")
        stdoutWomFile := womtype.NewWomFile(execUnit.StdoutFile())
        stderrWomFile := womtype.NewWomFile(execUnit.StderrFile())
        ctxt := wom.NewWomExecContext(stdoutWomFile, stderrWomFile)
        ctxt.SetWorkdir(workDir)
        ctxt.SetIOCoercer(WdlIOLibraryCoercer)
        ctxt.SetCommandCoercer(func (womValue womtype.WomValue,
            ctxt wom.CommandCoerceCtxt)(string, wom.CommandCoerceCtxt) {
                return WdlCommandFileCoercer(womValue, ctxt, job)
            })
        ctxt.EnableCoerceFile(true)
        ctxt.SetPathChecker(WdlFilePathChecker)

        /*Get the docker image*/
        HandleRuntimeAttributes(womStage, execUnit.RuntimeAttributes())


        issuedStages[stageId] = womStage
        womScheduler.lock.Lock()
        womScheduler.execUnits[stageId] = &ExecUnitInfo{
                stage: womStage,
                unit: execUnit,
                ctxt: ctxt,
        }
        womScheduler.lock.Unlock()
    }

    /*re-issue the retry units*/
    womScheduler.lock.Lock()
    for _, unitInfo := range womScheduler.needRetryUnits {
        stage := unitInfo.stage
        womScheduler.execUnits[stage.GetID()] = unitInfo
        delete(womScheduler.needRetryUnits, stage.GetID())
        issuedStages[stage.GetID()] = stage
    }
    womScheduler.lock.Unlock()

    if state == engine.GRAPH_STATE_PROCESSED && len(issuedStages) == 0 {
        SchedulerLogger.Infof("Wom graph of job %s processed and no issue stages, retry it\n",
            job.GetID())
        goto retrySchedule
    }

    /*Need handle the stages collected in the recovery phase*/
    if recoveredStages := womScheduler.RecoveredStages(); recoveredStages != nil {
        for stageId, stage := range recoveredStages {
            issuedStages[stageId] = stage
        }
    }

    SchedulerLogger.Debugf("Finish schedule wom graph of job %s, issue %d stages\n",
        job.GetID(), len(issuedStages))

    if len(issuedStages) > 0 {
        return issuedStages, JOB_GRAPH_PENDING, nil
    }

    retState := womScheduler._EvaluateGraphState(state)

    return issuedStages, retState, nil
}

func (womScheduler *womGraphScheduler)HandleGraphEvent(stageId string, event GraphEvent) error {
    unitInfo := womScheduler.FindExecUnit(stageId)
    if unitInfo == nil {
        return errors.New("Unknown pending stage id " + stageId)
    }

    switch event {
        case GRAPH_EVENT_DONE:
            /*change exec unit state*/
            womScheduler.ClearRecoveredStage(stageId)
            SchedulerLogger.Debugf("Handle Wom Graph Event Done for stage %s",
                stageId)
            output, err := womScheduler.womEngine.HandleExecUnitEvent(unitInfo.unit,
                unitInfo.ctxt, engine.EXEC_EVENT_DONE)
            if err == nil {
                if output != nil {
                    unitInfo.stage.SetTargetOutputs(output.Values())
                }
                womScheduler.ChangeExecUnitState(stageId, EXEC_UNIT_DONE)
            } else {
                womScheduler.ChangeExecUnitState(stageId, EXEC_UNIT_FORBIDDEN)
            }
            return err
        case GRAPH_EVENT_FAIL, GRAPH_EVENT_LOST:
            womScheduler.ChangeExecUnitState(stageId, EXEC_UNIT_RETRY)
            womScheduler.ClearRecoveredStage(stageId)
            SchedulerLogger.Debugf("Handle Wom Graph Event Fail/Lost for stage %s\n",
                stageId)
        case GRAPH_EVENT_SUBMIT_FAIL:
            womScheduler.ChangeExecUnitState(stageId, EXEC_UNIT_RETRY)
            womScheduler.ClearRecoveredStage(stageId)
            SchedulerLogger.Debugf("Handle Wom Graph Event Submit Fail for stage %s\n",
                stageId)
        case GRAPH_EVENT_FORBIDDEN:
            womScheduler.ChangeExecUnitState(stageId, EXEC_UNIT_FORBIDDEN)
            womScheduler.ClearRecoveredStage(stageId)
            SchedulerLogger.Debugf("Handle Wom Graph Event Forbidden for stage %s\n",
                stageId)
        case GRAPH_EVENT_SUBMITTED, GRAPH_EVENT_RUNNING, GRAPH_EVENT_QUEUED:
            /*Should marked the recovered stages already scheduled and not issue it again*/
            womScheduler.ClearRecoveredStage(stageId)
        default:
            SchedulerLogger.Debugf("Don't handle unknown wom graph event for stage %s\n",
                stageId)
    }

    return nil
}

func (womScheduler *womGraphScheduler) StageCount() int {
    return 0
}

func (womScheduler *womGraphScheduler) GetWaitingStages() ([]Stage, []Stage) {
     return nil, nil
}

func (womScheduler *womGraphScheduler) Fini() error {
    if womScheduler.womEngine != nil {
        return womScheduler.womEngine.Fini()
    }

    return nil
}

/*return workflow's output as job output*/
func (womScheduler *womGraphScheduler) GetOutput() (*JobOutput, error) {
    if womScheduler.womEngine != nil {
        womOutputs, err := womScheduler.womEngine.EvaluateOutput()
        if err != nil {
            return nil, err
        }
        outputValues := make(map[string]string)
        for key, womValue := range womOutputs {
            if womValue != nil {
                outputValues[key] = womValue.String()
            } else {
                outputValues[key] = "nil"
            }
        }
        return NewJobOutput(outputValues), nil
    }
    return nil, errors.New("wom engine not ready")
}

func NewWomGraphScheduler(job Job, pipeline Pipeline) *womGraphScheduler {
    return &womGraphScheduler{
            job: job,
            pipeline: pipeline,
            womEngine: nil,
            execUnits: make(map[string]*ExecUnitInfo),
            needRetryUnits: make(map[string]*ExecUnitInfo),
            forbiddenUnits: make(map[string]*ExecUnitInfo),
            recoveredStages: make(map[string]Stage),
    }
}
